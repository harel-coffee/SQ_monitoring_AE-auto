{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Service Quality Monitoring in Confined Spaces Through Mining Twitter Data\n",
    "The proposed method comprises of two main tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Aspect Extraction using fine-tuned BERT language model\n",
    "In this notebook, we use the BERT approach to transform tweets into a vector of words. Then, using a binary classifier, multi-label tweets can be classified into semantically-related groups, i.e., service quality aspects in our application. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from data_from_csv import *\n",
    "from getting_data_ready import *\n",
    "from PaddingInputExample import *\n",
    "from InputExample import *\n",
    "from InputFeatures import *\n",
    "from BERT import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safety:  134\n",
      "CleanlinessView:  133\n",
      "Information:  146\n",
      "Service:  739\n",
      "Comfort:  196\n",
      "PersonnelCard:  66\n",
      "Additional:  205\n"
     ]
    }
   ],
   "source": [
    "csv_file = data_from_csv(os.path.join(\"Data\",'SouthernCross.csv'))\n",
    "data = csv_file.read_csv()\n",
    "csv_file.report_on_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready = getting_data_ready(data, 0.1)\n",
    "X_train, y_train, X_test, y_test = data_ready.splitting_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Ready the Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safety:  4200\n",
      "CleanlinessView:  4200\n",
      "Information:  4200\n",
      "Service:  6000\n",
      "Comfort:  4200\n",
      "PersonnelCard:  4800\n",
      "Additional:  2400\n"
     ]
    }
   ],
   "source": [
    "X_resampled, y_resampled = data_ready.resampling_data(X_train, y_train)\n",
    "x_train_resampled = data_ready.resampled_to_table(X_resampled, y_resampled)\n",
    "data_ready.report_on_resampled_classes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Ready the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data_ready.to_table(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bert\\tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_path = \"uncased_L-12_H-768_A-12\\\\\"\n",
    "output_path = 'bert-output'\n",
    "bert_class = BERT(bert_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google-pasta==0.1.6\n",
    "# pip install gast==0.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\OneDrive - The University of Melbourne\\PhD\\Tools\\python_projects\\BERT\\BERT.py:446: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\OneDrive - The University of Melbourne\\PhD\\Tools\\python_projects\\BERT\\BERT.py:543: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:***** Running training *****\n",
      "INFO:tensorflow:  Num examples = 16800\n",
      "INFO:tensorflow:  Batch size = 32\n",
      "INFO:tensorflow:  Num steps = 525\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\OneDrive - The University of Melbourne\\PhD\\Tools\\python_projects\\BERT\\BERT.py:480: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'bert-output', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001EE226C99C8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "Beginning Training!\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\OneDrive - The University of Melbourne\\PhD\\Tools\\python_projects\\BERT\\BERT.py:516: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\data\\python\\ops\\batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\OneDrive - The University of Melbourne\\PhD\\Tools\\python_projects\\BERT\\BERT.py:489: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\OneDrive - The University of Melbourne\\PhD\\Tools\\python_projects\\BERT\\BERT.py:496: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bert\\modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bert\\modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bert\\modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bert\\modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bert\\modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "INFO:tensorflow:num_labels:7;logits:Tensor(\"loss/BiasAdd:0\", shape=(32, 7), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(32, 7), dtype=float32)\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\OneDrive - The University of Melbourne\\PhD\\Tools\\python_projects\\BERT\\BERT.py:243: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bert\\optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\bert\\optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from bert-output\\model.ckpt-0\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into bert-output\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.72407407, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.0341819\n",
      "INFO:tensorflow:loss = 0.17010844, step = 101 (2925.530 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 128 vs previous value: 128. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 130 vs previous value: 130. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.0382175\n",
      "INFO:tensorflow:loss = 0.06770197, step = 201 (2616.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.0382161\n",
      "INFO:tensorflow:loss = 0.056423012, step = 301 (2616.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.0382181\n",
      "INFO:tensorflow:loss = 0.07670855, step = 401 (2616.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.0381699\n",
      "INFO:tensorflow:loss = 0.05395896, step = 501 (2619.862 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 525 into bert-output\\model.ckpt.\n",
      "WARNING:tensorflow:From C:\\Users\\mmrahimi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Loss for final step: 0.035924464.\n",
      "Training took time  3:56:16.682455\n"
     ]
    }
   ],
   "source": [
    "bert_class.train_bert(x_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Predictions!\n",
      "Prediction took time  0:00:00.000995\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:7;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 7), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 7), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "mode: infer probabilities: Tensor(\"loss/Sigmoid:0\", shape=(?, 7), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from bert-output\\model.ckpt-525\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72        13\n",
      "           1       0.67      0.46      0.55        13\n",
      "           2       0.60      0.60      0.60        15\n",
      "           3       0.87      0.89      0.88        74\n",
      "           4       0.64      0.45      0.53        20\n",
      "           5       0.50      0.14      0.22         7\n",
      "           6       0.80      0.57      0.67        21\n",
      "\n",
      "   micro avg       0.78      0.69      0.73       163\n",
      "   macro avg       0.69      0.54      0.59       163\n",
      "weighted avg       0.77      0.69      0.72       163\n",
      " samples avg       0.48      0.47      0.47       163\n",
      "\n",
      "F1 micro averaging: 0.7320261437908496\n",
      "ROC:  0.7586641100707713\n"
     ]
    }
   ],
   "source": [
    "test_labels = bert_class.testing_model(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report_as_df(report):\n",
    "    cl_results = report.split()[4:39]\n",
    "    cl_results_rest = report.split()[39:]\n",
    "    df = pd.DataFrame(columns=['P','R','F'])\n",
    "    for i in range(0,len(cl_results),5):\n",
    "        df.loc[len(df)] = cl_results[i+1:i+4]\n",
    "\n",
    "    for i in range(0,len(cl_results_rest),6):\n",
    "        df.loc[len(df)] = cl_results_rest[i+2:i+5]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def mean_std_from_results(reports_dic):\n",
    "    mean_result = pd.DataFrame(columns=['P','R','F'])\n",
    "    std_result = pd.DataFrame(columns=['P','R','F'])\n",
    "    for j in range(0,len(reports_dic[1])): # for each aspect\n",
    "        df = pd.DataFrame(columns=['P','R','F'])\n",
    "        for i in reports_dic: # for each fold\n",
    "            df.loc[len(df)] = list(reports_dic[i].loc[j])\n",
    "        df = df.apply(pd.to_numeric)\n",
    "        mean_result.loc[len(mean_result)] = df.mean()\n",
    "        std_result.loc[len(std_result)] = df.std()\n",
    "    return mean_result, std_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safety:  75\n",
      "CleanlinessView:  21\n",
      "Information:  194\n",
      "Service:  948\n",
      "Comfort:  117\n",
      "PersonnelCard:  107\n",
      "Additional:  16\n"
     ]
    }
   ],
   "source": [
    "eval_csv_file = data_from_csv(os.path.join(\"Data\",'Flinders.csv'))\n",
    "eval_data = eval_csv_file.read_csv()\n",
    "eval_csv_file.report_on_classes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Predictions!\n",
      "Prediction took time  0:00:00.000997\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:num_labels:7;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 7), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 7), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "mode: infer probabilities: Tensor(\"loss/Sigmoid:0\", shape=(?, 7), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from bert-output\\model.ckpt-525\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.41      0.56        75\n",
      "           1       0.43      0.29      0.34        21\n",
      "           2       0.68      0.83      0.75       194\n",
      "           3       0.92      0.92      0.92       948\n",
      "           4       0.63      0.43      0.51       117\n",
      "           5       0.74      0.50      0.59       107\n",
      "           6       0.83      0.31      0.45        16\n",
      "\n",
      "   micro avg       0.85      0.80      0.82      1478\n",
      "   macro avg       0.73      0.53      0.59      1478\n",
      "weighted avg       0.84      0.80      0.81      1478\n",
      " samples avg       0.76      0.76      0.75      1478\n",
      "\n",
      "F1 micro averaging: 0.8227098571926159\n",
      "ROC:  0.7389927372254645\n"
     ]
    }
   ],
   "source": [
    "eval_data = eval_data.reset_index(drop=True)\n",
    "eval_labels = bert_class.testing_model(eval_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
